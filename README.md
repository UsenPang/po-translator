# 项目名称：PO-Translator
## 项目简介：
PO-Translator 是一个基于大语言模型（LLM）的自动化翻译工具，专门用于处理 .po 文件的国际化（i18n）和本地化（l10n）任务。该项目利用先进的大语言模型（如 kimi、deepseek、qwen、glm、openai 或其他类似模型）提供高质量的翻译，同时结合 Python 编程语言的强大功能，为开发者和翻译团队提供了一个高效、智能的解决方案。  
## 主要功能：
- 智能翻译：利用大语言模型（LLM）进行高质量的自动翻译，支持多种语言。
- 自动翻译：支持从源语言（如英语）到目标语言（如中文、法语等）的自动翻译。
- 多语言支持：支持多种目标语言，满足不同地区和用户的需求。
- 文件管理：自动处理 .po 文件的读取、翻译和保存，支持批量处理。

## 使用场景：
- 软件开发：帮助开发者快速完成软件的国际化和本地化任务。
- 翻译团队：提高翻译效率，减少重复工作。
- 多语言项目：适用于需要支持多种语言的软件项目。

## 如何使用：
安装依赖：
```bash
pip install -r requirements.txt
```
配置环境变量：  
编辑 .env 文件，配置翻译 API 密钥和其他参数。
运行脚本：  
```
python main.py
```
查看输出：  
翻译后的 .po 文件将保存到指定目录。  

## 更多模型：
该程序已经内置了一些默认模型可供选择，如有更多的模型需求，请编辑config.py
```python
MODEL_CONFIG_DICT = {
    'kimi-128k': {
        'model': 'moonshot-v1-128k',
        'base_url': 'https://api.moonshot.cn/v1',
        'prompt': PROMPT,
        'temperature': 0.3,
        'rpm': 3,
    }
}
```
将会根据你环境变量中的`MODEL`找到对应的配置。  

temperature：采样温度，较高的值将使输出更加随机，而较低的值将使其更加集中和确定性。调整该参数会影响翻译的效果。  
prompt：提示词，其中prompt也是影响翻译效果的一大因素。  
rpm：每分钟调用的次数，模型api调用会有限速，不同的模型限制不一样。  

**注意**：以上的模型api应该支持openai SDK的调用。